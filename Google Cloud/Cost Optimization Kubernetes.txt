-- Pod disruption budget

kubectl create poddisruptionbudget onlineboutique-frontend-pdb --selector run=frontend --min-available 1 --namespace dev

-- Delete a pod

kubectl delete pod gb-frontend

-- Set default region/zone

gcloud config set compute/zone us-central1-a

-----Migrating to a new node pool------------------------------------------------------------------
-- Create a node pool

gcloud container node-pools create optimized-pool-4642 \
  --cluster=onlineboutique-cluster-204 \
  --machine-type=custom-2-3584 \
  --num-nodes=2 \
  --zone=us-central1-a

-- cordon the original node pool:
for node in $(kubectl get nodes -l cloud.google.com/gke-nodepool=default-pool -o=name); do
  kubectl cordon "$node";
done

-- drain the pool:
for node in $(kubectl get nodes -l cloud.google.com/gke-nodepool=default-pool -o=name); do
  kubectl drain --force --ignore-daemonsets --delete-local-data --grace-period=10 "$node";
done

-- delete the old node pool:
gcloud container node-pools delete default-pool --cluster onlineboutique-cluster-204 --zone us-central1-a

-- See which pods are running:
kubectl get pods -o=wide

------------------------------------------------------------------------------------------------------

-- SSH to a pod:
kubectl exec -it pod-1 -- sh

-- Ping a pod:
ping [POD-2-IP]:8080

-- Get nodes
kubectl get nodes

-- Enable Node auto provisioning
gcloud container clusters update scaling-demo \
    --enable-autoprovisioning \
    --min-cpu 1 \
    --min-memory 2 \
    --max-cpu 45 \
    --max-memory 160

-- Apply horizontal autoscaling to the frontend deployment:

kubectl autoscale deployment frontend --cpu-percent=50 --min=1 --max=10 --namespace dev
kubectl get hpa --namespace dev

-- Check the current status of your Horizontal Pod Autoscaler:
kubectl get hpa

-- Enable Vertical Pod Autoscaling: 
gcloud container clusters update scaling-demo --enable-vertical-pod-autoscaling

-- Assign a CPU resource request of 450m to the deployment:
kubectl set resources deployment hello-server --requests=cpu=450m

-- Scale hello-server deployment to 2 replicas:
kubectl scale deployment hello-server --replicas=2

-- Enable autoscaling for your cluster:
gcloud beta container clusters update onlineboutique-cluster-204 --enable-autoscaling --min-nodes 1 --max-nodes 6 --zone=us-central1-a

-- Enable Node Auto Provisioning:
gcloud container clusters update scaling-demo \
    --enable-autoprovisioning \
    --min-cpu 1 \
    --min-memory 2 \
    --max-cpu 45 \
    --max-memory 160

-- Create 2 namespaces for dev and prod:
kubectl create namespace dev && \
kubectl create namespace prod

-- List of namespaces
kubectl get namespace

-- deploy a pod in the team-a namespace and in the team-b namespace using the same name:
kubectl run app-server --image=centos --namespace=team-a -- sleep infinity && \
kubectl run app-server --image=centos --namespace=team-b -- sleep infinity

-- To create and enroll a Standard cluster in a specific release channel:
gcloud container clusters create CLUSTER_NAME \
    --zone COMPUTE_ZONE \
    --release-channel CHANNEL \
    ADDITIONAL_FLAGS

-- create a new regional cluster
gcloud container clusters create regional-demo --region=us-central1 --num-nodes=1

-- Apply the newly created manifest php-apache.yaml to your cluster
kubectl apply -f php-apache.yaml

-- Create cluster
gcloud container clusters create onlineboutique-cluster-204 \
   --machine-type=n1-standard-2 \
  --num-nodes=2 \
  --zone=us-central1-a  \
  --release-channel rapid


